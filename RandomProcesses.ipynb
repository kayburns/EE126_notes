{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Time Markov Chains - PageRank\n",
    "\n",
    "If I want to characterize the complete behavior of a DTMC, all I need is the joint PMF. Markov chains are memoryless, so this probability can be expressed as the product of conidtional probabilites.\n",
    "\n",
    "#### Markov Property\n",
    "\n",
    "Given the last state, Markov chains have no memory of the history of the process.\n",
    "\n",
    "$$\\Pr(X_n|X_{n-1}, \\ldots, X_1) = \\Pr(X_n|X_{n - 1})$$\n",
    "\n",
    "*(e.g.) Verifying the Markov property*\n",
    "\n",
    "Does the sequence $\\{Y_1, Y_2, \\ldots \\}$ such that $Y_{n + 1} = (Y_n + X_{n + 1})^{(n + 1)}$ obey the Markov property?\n",
    "\n",
    "This obeys the Markov property. $X$ are mutually independent and our expression only depends on $Y_n$.\n",
    "\n",
    "#### Irreducibility\n",
    "\n",
    "We can reach any state from any other state.\n",
    "\n",
    "#### Periodicity\n",
    "\n",
    "There is no long term pattern to the sequence of visits made to any state.\n",
    "\n",
    "$$d(i) = \\text{g.c.d.}\\{n\\geq 1|P^n(i, i)>0\\}$$\n",
    "\n",
    "If $d(i) = 1$, then the Markov chain is aperiodic.\n",
    "\n",
    "#### Invariant Distribution: Big Theorem for Markov Chains\n",
    "\n",
    "All finite Markov chains have an invariant distribution: $\\pi = \\pi P$. This represents the long term average amount of time spent in each state.\n",
    "\n",
    "1. if MC is finite and irreducible, it has a unique invariant distribution $\\pi^*$\n",
    "\n",
    "2. if MC is periodic, then $\\lim_{n\\rightarrow\\infty}\\pi_n = \\pi^*$\n",
    "\n",
    "#### Hitting Time\n",
    "\n",
    "What is the average number of transition to get to state X?\n",
    "\n",
    "$$\\beta(i) = E[T_X|X_0 = A]$$\n",
    "\n",
    "$$\\beta(i) = 1 + \\sum_jP(i, j)\\beta(j)$$\n",
    "\n",
    "#### Reversible Markov Chains\n",
    "\n",
    "In reversible Markov chains, instead of moving forward in time, we move backward: $X^r_{(i)} = X_{(t - i)}$\n",
    "\n",
    "Properties\n",
    "\n",
    "1. a reversed Markov chain is also a Markov chain with the same stationary distribution\n",
    "\n",
    "2. for a time reversed Markov chain to be the same as the forward Markov chain:\n",
    "\n",
    "$$\\pi(j)P_{j, i} = \\pi(i)P_{i, j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Process\n",
    "\n",
    "In a Poisson process, we count the number of arrivals at time $t$, $N_t$. Let $S_i$ be the interarrival time from $t_{i - 1}$ to $t_{i}$. $T_n = \\sum_{i = 1}^{n}S_i$.\n",
    "\n",
    "$$S_n \\sim Exp(\\lambda)$$\n",
    "\n",
    "$$N_t \\sim Pois(\\lambda t)$$\n",
    "\n",
    "Properties\n",
    "\n",
    "1. Poission process is memoryless.\n",
    "\n",
    "2. The probability of k arrivals in an interval of length t, $\\Pr(k, t)$, is the same for all t. By taylor series approximation, we see that for a small interval length $\\tau$:\n",
    "$$\\Pr(k, \\tau) = \\frac{\\lambda\\tau^k}{k!}(e^{-\\lambda\\tau}) = \\frac{\\lambda\\tau^k}{k!} \\sum_{i = 0}^\\infty \\frac{(-\\lambda\\tau)^i}{i!}$$\n",
    "$$\\Pr(0, \\tau) = 1 - \\lambda\\tau + o(\\tau)$$\n",
    "$$\\Pr(1, \\tau) = \\lambda\\tau + o_1(\\tau)$$\n",
    "$$\\Pr(2, \\tau) = o_k(\\tau)$$\n",
    "3. The distribution of the number of arrivals of a Poisson process with rate $\\lambda$ in an interval of length $t$ is $Pois(\\lambda t)$.\n",
    "\n",
    "$$\\Pr(N_t = k) = \\Pr(k, t) = (\\lambda t)^k\\frac{e^{-\\lambda t}}{k!}$$\n",
    "\n",
    "#### Properties of the $k^{th}$ Arrival Time\n",
    "\n",
    "- $Y_k = \\sum_{i = 1}^k T_i$\n",
    "- $E[Y_k] = \\sum_{i = 1}^k E[T_i] = \\frac k\\lambda$\n",
    "- $Var(Y_k) = \\sum_{i = 1}^k Var(T_i) = \\frac k{\\lambda^2}$\n",
    "- Erlang PDF of Order K: $f_{Y_k}(y) = \\lambda\\frac{(\\lambda y)^{k-1}e^{-\\lambda y}}{(k - 1)!}$\n",
    "\n",
    "#### Poisson Splitting\n",
    "\n",
    "Consider an $Pois(\\lambda)$ process in which an arrival is successfully received with probability $p$. This is a poisson process with rate $\\lambda p$.\n",
    "\n",
    "*(e.g.) Taxis arrive according to $PP(\\lambda)$ and stop with probability $p$. What is the distribution of the time that you wait?*\n",
    "\n",
    "This is a geometric number of exponential random variables. The probability that the $m^{th}$ taxi picks you up is $p(1 - p)^{m-1}$. The time it takes each taxi to arrive is $Exp(\\lambda)$.\n",
    "\n",
    "Using MGF, we proved that this is $Exp(\\lambda p)$. Now we can infer this from the distribution of the number of arrivals, which is $Pois(\\lambda p)$.\n",
    "\n",
    "#### Poisson Merging\n",
    "\n",
    "Consider two Poisson processes with rates $\\lambda$ and $\\mu$. The merging of these two processes is Poisson with rate $\\lambda + \\mu$. An arrival has probability $\\frac{\\lambda}{\\lambda + \\mu}$ and $\\frac{\\mu}{\\lambda + \\mu}$ of coming from the first and second process, respectively.\n",
    "\n",
    "Recall that the merging of two exponential distributions is exponential with rate $\\lambda_1 + \\lambda_2$.\n",
    "\n",
    "#### Random Incidence Paradox\n",
    "\n",
    "Consider an arrival process with rate $\\lambda$. We observe time $t$.\n",
    "\n",
    "The distribution of the time between the last and next arrival is the sum of $2$ exponential random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Time Markov Chains\n",
    "\n",
    "A continuous time Markov chain is a heterogeneous Poisson process. Arrival processes cause transitions to new states. We use a rate matrix, $Q(i, j) = \\lambda_{ij}$, to represent transition rates. We want to use the rate matrix to solve the balance equations (flow into the state should equal flow out), so we enforce the constraint that the rows sum to 0. Therefore:\n",
    "\n",
    "- The amount of time spent in any state is $Exp(\\sum_i \\lambda_i)$.\n",
    "\n",
    "- $q(i)$ is the sum of the rates out of $i$: $q(i) = \\sum_{j \\neq i} Q(i, j)$\n",
    "\n",
    "- The from $i$ to itself should balance the rate outward: $Q(i, i) = -q(i)$\n",
    "\n",
    "- The probability that the next transition goes to $j$: $\\Gamma(i, j) = \\frac{Q(i, j)}{q(i)}$\n",
    "\n",
    "\n",
    "- $\\Pr(X_{t + \\epsilon} = j|X_t = i, X_u, u\\leq t)=\\left\\{\n",
    "        \\begin{array}{ll}\n",
    "          P_j(1, \\tau) = \\epsilon Q(i, j),\\:\\forall j\\neq i\\\\\n",
    "          1 + \\epsilon Q(i, j), j = i\\\\\n",
    "        \\end{array}\n",
    "      \\right.\n",
    "  $\n",
    "\n",
    "#### Reduction to a DTMC\n",
    "\n",
    "<font color=\"red\">how to do?</font>\n",
    "\n",
    "#### Recurrence Properties and the Invariant\n",
    "\n",
    "Any Markov chain can be decomposed into communicating classes (strongly connected components). All of the states in a strongly connected components have the same recurrence property.\n",
    "\n",
    "- Null Recurrent\n",
    "\n",
    "$$\\sum_{x\\in S}\\mu(x) = \\infty$$\n",
    "\n",
    "If the MC is recurrent, it's guaranteed to return to the same state. $E_x[N(x)] = \\infty$\n",
    "\n",
    "Irreducible and recurrence implies the existence of a stationary distribution, $\\mu$: $\\mu P = \\mu$\n",
    "\n",
    "- Positive Recurrent\n",
    "\n",
    "$$\\sum_{x\\in S}\\mu(x) < \\infty$$\n",
    "\n",
    "If the MC is recurrent, it's guaranteed to return to the same state. $E_x[N(x)] = \\infty$\n",
    "\n",
    "Irreducible and recurrence implies the existence of a stationary distribution, $\\mu$: $\\mu P = \\mu$\n",
    "\n",
    "Positive recurrence implies the existence of a distribution $\\pi$, a scaled $\\mu$, to which it will always converge.\n",
    "\n",
    "*(e.g.) Proving positive recurrence*\n",
    "\n",
    "An online dating website tries to match couples. Let $X_n$ be the number of members of this site at time slot $n$. We want to analyze the discrete-time process $\\{X_n, n \\geq 0\\}$. At each time slot, exactly one of the following events happens: (i) Two persons are happily matched and leave the website forever with probability p, (ii) A single frustrated person leaves the system individually with probability q , and (iii) a new member joins the system with probability $r = 1−p−q$. If there is only one member in the system, that member leaves with probability\n",
    "$p + q = 1 − r$. Suppose that $r − q − 2p > 0$: is the Markov Chain $\\{X_n, n \\geq 0\\}$\n",
    "positive recurrent, null recurrent, or transient? Prove your answer.\n",
    "\n",
    "\n",
    "\n",
    "- Transient\n",
    "\n",
    "If the MC is transient, it's not guaranteed to return to the same state. $E_x[N(x)] < \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
